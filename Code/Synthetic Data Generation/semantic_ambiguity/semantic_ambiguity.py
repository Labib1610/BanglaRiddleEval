#!/usr/bin/env python3
"""
Semantic Ambiguity Task Generator for Bengali Riddles
===================================================

This script creates semantic ambiguity tasks from riddles.json, identifying
ambiguous words/metaphors in riddles and generating multiple choice questions
about what those words refer to in the context of the riddle.

Features:
- Robust error handling with retry mechanism
- Progress tracking and resume capability
- Failed riddles tracking for manual review
- Time-stamped saves and comprehensive logging

Author: AI Assistant
Date: November 2025
"""

import json
import requests
import time
import os
import random
from typing import Dict, List, Optional, Any

# Configuration
OLLAMA_MODEL = "gpt-oss:20b"
OLLAMA_URL = "http://localhost:11434/api/generate"

# File paths
BASE_PATH = "/mnt/wwn-0x500a0751e14d807e-part2/Labib/Labib Folder/Labib/Research/BornoDhada"
RIDDLES_FILE = f"{BASE_PATH}/dataset/riddles.json"
OUTPUT_FILE = f"{BASE_PATH}/dataset/riddles_semantic_ambiguity.json"
PROGRESS_FILE = f"{BASE_PATH}/dataset/semantic_progress.json"
FAILED_FILE = f"{BASE_PATH}/dataset/semantic_failed.json"

class SemanticAmbiguityGenerator:
    """
    Generates semantic ambiguity tasks for Bengali riddles using Ollama gpt-oss:20b model.
    """
    
    def __init__(self):
        self.processed_riddles = set()
        self.failed_riddles = []
        self.load_existing_data()
    
    def load_existing_data(self):
        """Load existing semantic ambiguity data and progress."""
        if os.path.exists(OUTPUT_FILE):
            try:
                with open(OUTPUT_FILE, 'r', encoding='utf-8') as f:
                    existing_tasks = json.load(f)
                    self.processed_riddles = {task['id'] for task in existing_tasks}
                print(f"üìä Loaded {len(self.processed_riddles)} existing semantic ambiguity tasks.")
            except Exception as e:
                print(f"‚ùå Error loading existing tasks: {e}")
        
        if os.path.exists(PROGRESS_FILE):
            try:
                with open(PROGRESS_FILE, 'r', encoding='utf-8') as f:
                    progress = json.load(f)
                    if 'failed_riddles' in progress:
                        self.failed_riddles = progress['failed_riddles']
                print(f"üìä Loaded progress with {len(self.failed_riddles)} previously failed riddles.")
            except Exception as e:
                print(f"‚ùå Error loading progress: {e}")
    
    def save_progress(self):
        """Save current progress."""
        progress = {
            'processed_count': len(self.processed_riddles),
            'failed_riddles': self.failed_riddles,
            'failed_count': len(self.failed_riddles),
            'last_updated': time.strftime("%Y-%m-%d %H:%M:%S")
        }
        with open(PROGRESS_FILE, 'w', encoding='utf-8') as f:
            json.dump(progress, f, indent=2, ensure_ascii=False)
    
    def save_failed_riddle(self, riddle_data: Dict[str, Any], error_message: str):
        """Save failed riddle for later analysis."""
        failed_entry = {
            'riddle_id': riddle_data.get('riddle_id'),
            'riddle': riddle_data.get('riddle'),
            'ans': riddle_data.get('ans'),
            'error': error_message,
            'timestamp': time.strftime("%Y-%m-%d %H:%M:%S")
        }
        
        # Load existing failed riddles
        failed_riddles = []
        if os.path.exists(FAILED_FILE):
            try:
                with open(FAILED_FILE, 'r', encoding='utf-8') as f:
                    failed_riddles = json.load(f)
            except Exception:
                pass
        
        failed_riddles.append(failed_entry)
        
        with open(FAILED_FILE, 'w', encoding='utf-8') as f:
            json.dump(failed_riddles, f, indent=2, ensure_ascii=False)
    
    def validate_task_quality(self, question: str, options: List[str], correct_option: str, riddle: str) -> bool:
        """Validate if the generated semantic ambiguity task meets quality criteria."""
        
        # Check for duplicate options
        if len(set(options)) != len(options):
            print(f"    ‚ùå Duplicate options found")
            return False
        
        # Check if correct option is in the options list
        if correct_option not in options:
            print(f"    ‚ùå Correct option '{correct_option}' not found in options")
            return False
        
        # Check if we have exactly 4 options
        if len(options) != 4:
            print(f"    ‚ùå Expected 4 options, got {len(options)}")
            return False
        
        # Check if question is asking about semantic meaning (in Bengali)
        if "‡¶¨‡ßã‡¶ù‡¶æ‡¶Ø‡¶º" not in question and "‡¶Ö‡¶∞‡ßç‡¶•" not in question and "‡¶®‡¶ø‡¶∞‡ßç‡¶¶‡ßá‡¶∂ ‡¶ï‡¶∞‡ßá" not in question:
            print(f"    ‚ö†Ô∏è  Question might not be about semantic meaning")
        
        # Check if options are too similar (simple string similarity)
        for i, opt1 in enumerate(options):
            for j, opt2 in enumerate(options[i+1:], i+1):
                if opt1.lower().strip() == opt2.lower().strip():
                    print(f"    ‚ùå Identical options: '{opt1}' and '{opt2}'")
                    return False
        
        print(f"    ‚úÖ Task validation passed")
        return True
    
    def check_ollama_connection(self) -> bool:
        """Check if Ollama is running and accessible."""
        print("üîç Checking Ollama connection...")
        
        try:
            response = requests.post(OLLAMA_URL, json={
                "model": OLLAMA_MODEL,
                "prompt": "Test",
                "stream": False,
                "options": {"max_tokens": 1}
            }, timeout=120)
            
            if response.status_code == 200:
                print("‚úÖ Ollama connection successful!")
                return True
            else:
                print(f"‚ùå Ollama connection failed with status: {response.status_code}")
                return False
                
        except requests.exceptions.Timeout:
            print(f"‚ùå Connection timeout. The model might be loading - try again in a moment.")
            return False
        except requests.exceptions.ConnectionError:
            print(f"‚ùå Cannot connect to Ollama. Make sure 'ollama serve' is running.")
            return False
        except Exception as e:
            print(f"‚ùå Ollama connection error: {e}")
            return False
    
    def generate_semantic_task(self, riddle: str, correct_answer: str) -> Optional[Dict[str, Any]]:
        """Generate semantic ambiguity task using Ollama model."""
        
        prompt = f"""‡¶Ü‡¶™‡¶®‡¶ø ‡¶è‡¶ï‡¶ú‡¶® ‡¶¨‡¶ø‡¶∂‡ßá‡¶∑‡¶ú‡ßç‡¶û ‡¶¨‡¶æ‡¶Ç‡¶≤‡¶æ ‡¶≠‡¶æ‡¶∑‡¶æ‡¶¨‡¶ø‡¶¶ ‡¶è‡¶¨‡¶Ç ‡¶ß‡¶æ‡¶Å‡¶ß‡¶æ ‡¶¨‡¶ø‡¶∂‡ßç‡¶≤‡ßá‡¶∑‡¶ï‡•§ ‡¶Ü‡¶™‡¶®‡¶æ‡¶∞ ‡¶ï‡¶æ‡¶ú ‡¶π‡¶≤ ‡¶¨‡¶æ‡¶Ç‡¶≤‡¶æ ‡¶ß‡¶æ‡¶Å‡¶ß‡¶æ‡¶Ø‡¶º ‡¶•‡¶æ‡¶ï‡¶æ ‡¶∞‡ßÇ‡¶™‡¶ï ‡¶¨‡¶æ ‡¶¶‡ßç‡¶¨‡ßç‡¶Ø‡¶∞‡ßç‡¶•‡¶ï ‡¶∂‡¶¨‡ßç‡¶¶ ‡¶ñ‡ßÅ‡¶Å‡¶ú‡ßá ‡¶¨‡ßá‡¶∞ ‡¶ï‡¶∞‡ßá ‡¶∏‡ßá‡¶ó‡ßÅ‡¶≤‡ßã ‡¶®‡¶ø‡¶Ø‡¶º‡ßá semantic ambiguity (‡¶Ö‡¶∞‡ßç‡¶•‡¶ó‡¶§ ‡¶Ö‡¶∏‡ßç‡¶™‡¶∑‡ßç‡¶ü‡¶§‡¶æ) ‡¶™‡ßç‡¶∞‡¶∂‡ßç‡¶® ‡¶§‡ßà‡¶∞‡¶ø ‡¶ï‡¶∞‡¶æ‡•§

‡¶ß‡¶æ‡¶Å‡¶ß‡¶æ: "{riddle}"
‡¶∏‡¶†‡¶ø‡¶ï ‡¶â‡¶§‡ßç‡¶§‡¶∞: "{correct_answer}"

**‡¶ï‡¶æ‡¶ú‡ßá‡¶∞ ‡¶ß‡¶æ‡¶™:**

‡ßß. ‡¶ß‡¶æ‡¶Å‡¶ß‡¶æ‡¶Ø‡¶º ‡¶∞‡ßÇ‡¶™‡¶ï ‡¶¨‡¶æ ‡¶¶‡ßç‡¶¨‡ßç‡¶Ø‡¶∞‡ßç‡¶•‡¶ï ‡¶∂‡¶¨‡ßç‡¶¶ ‡¶ö‡¶ø‡¶π‡ßç‡¶®‡¶ø‡¶§ ‡¶ï‡¶∞‡ßÅ‡¶® (‡¶Ø‡ßá‡¶Æ‡¶®: ‡¶ü‡¶ø‡¶Ø‡¶º‡ßá, ‡¶∏‡ßã‡¶®‡¶æ‡¶∞ ‡¶ü‡ßã‡¶™‡¶∞, ‡¶¨‡ßá‡¶∞‡ßÅ‡¶≤ ‡¶á‡¶§‡ßç‡¶Ø‡¶æ‡¶¶‡¶ø)
‡ß®. **‡¶ó‡ßÅ‡¶∞‡ßÅ‡¶§‡ßç‡¶¨‡¶™‡ßÇ‡¶∞‡ßç‡¶£**: ‡¶¶‡ßç‡¶¨‡ßç‡¶Ø‡¶∞‡ßç‡¶•‡¶ï ‡¶∂‡¶¨‡ßç‡¶¶‡¶ü‡¶ø ‡¶Ö‡¶¨‡¶∂‡ßç‡¶Ø‡¶á ‡¶ß‡¶æ‡¶Å‡¶ß‡¶æ‡¶∞ ‡¶Æ‡¶ß‡ßç‡¶Ø‡ßá ‡¶•‡ßá‡¶ï‡ßá ‡¶®‡¶ø‡¶§‡ßá ‡¶π‡¶¨‡ßá, ‡¶â‡¶§‡ßç‡¶§‡¶∞ "{correct_answer}" ‡¶•‡ßá‡¶ï‡ßá ‡¶®‡¶Ø‡¶º
‡ß©. ‡¶∏‡¶¨‡¶ö‡ßá‡¶Ø‡¶º‡ßá ‡¶Ü‡¶ï‡¶∞‡ßç‡¶∑‡¶£‡ßÄ‡¶Ø‡¶º ‡¶è‡¶¨‡¶Ç ‡¶¶‡ßç‡¶¨‡ßç‡¶Ø‡¶∞‡ßç‡¶•‡¶ï ‡¶è‡¶ï‡¶ü‡¶ø ‡¶∂‡¶¨‡ßç‡¶¶/‡¶¨‡¶æ‡¶ï‡ßç‡¶Ø‡¶æ‡¶Ç‡¶∂ ‡¶¨‡ßá‡¶õ‡ßá ‡¶®‡¶ø‡¶® ‡¶Ø‡¶æ ‡¶ß‡¶æ‡¶Å‡¶ß‡¶æ‡¶∞ ‡¶ü‡ßá‡¶ï‡ßç‡¶∏‡¶ü‡ßá ‡¶Ü‡¶õ‡ßá
‡ß™. ‡¶∏‡ßá‡¶á ‡¶∂‡¶¨‡ßç‡¶¶‡¶ü‡¶ø ‡¶ß‡¶æ‡¶Å‡¶ß‡¶æ‡¶∞ ‡¶™‡ßç‡¶∞‡ßá‡¶ï‡ßç‡¶∑‡¶ø‡¶§‡ßá ‡¶Ü‡¶∏‡¶≤‡ßá ‡¶ï‡ßÄ ‡¶¨‡ßã‡¶ù‡¶æ‡¶Ø‡¶º ‡¶§‡¶æ ‡¶®‡¶ø‡¶Ø‡¶º‡ßá ‡¶™‡ßç‡¶∞‡¶∂‡ßç‡¶® ‡¶§‡ßà‡¶∞‡¶ø ‡¶ï‡¶∞‡ßÅ‡¶®
‡ß´. ‡ß™‡¶ü‡¶ø ‡¶¨‡¶ø‡¶ï‡¶≤‡ßç‡¶™ ‡¶â‡¶§‡ßç‡¶§‡¶∞ ‡¶¶‡¶ø‡¶® ‡¶Ø‡¶æ‡¶∞ ‡¶Æ‡¶ß‡ßç‡¶Ø‡ßá ‡ßß‡¶ü‡¶ø ‡¶∏‡¶†‡¶ø‡¶ï ‡¶è‡¶¨‡¶Ç ‡ß©‡¶ü‡¶ø ‡¶Ø‡ßÅ‡¶ï‡ßç‡¶§‡¶ø‡¶∏‡¶Ç‡¶ó‡¶§ ‡¶ï‡¶ø‡¶®‡ßç‡¶§‡ßÅ ‡¶≠‡ßÅ‡¶≤

**‡¶â‡¶¶‡¶æ‡¶π‡¶∞‡¶£ ‡¶¨‡¶ø‡¶∂‡ßç‡¶≤‡ßá‡¶∑‡¶£:**
‡¶ß‡¶æ‡¶Å‡¶ß‡¶æ: "‡¶¨‡¶® ‡¶•‡ßá‡¶ï‡ßá ‡¶¨‡ßá‡¶∞‡ßÅ‡¶≤ ‡¶ü‡¶ø‡¶Ø‡¶º‡ßá ‡¶∏‡ßã‡¶®‡¶æ‡¶∞ ‡¶ü‡ßã‡¶™‡¶∞ ‡¶Æ‡¶æ‡¶•‡¶æ‡¶Ø‡¶º ‡¶¶‡¶ø‡¶Ø‡¶º‡ßá‡•§"
‡¶â‡¶§‡ßç‡¶§‡¶∞: "‡¶Ü‡¶®‡¶æ‡¶∞‡¶∏"

‡¶¶‡ßç‡¶¨‡ßç‡¶Ø‡¶∞‡ßç‡¶•‡¶ï ‡¶∂‡¶¨‡ßç‡¶¶ ‡¶¨‡¶ø‡¶∂‡ßç‡¶≤‡ßá‡¶∑‡¶£:
- "‡¶ü‡¶ø‡¶Ø‡¶º‡ßá" = ‡¶Ü‡¶ï‡ßç‡¶∑‡¶∞‡¶ø‡¶ï ‡¶Ö‡¶∞‡ßç‡¶•‡ßá ‡¶™‡¶æ‡¶ñ‡¶ø, ‡¶ï‡¶ø‡¶®‡ßç‡¶§‡ßÅ ‡¶Ü‡¶®‡¶æ‡¶∞‡¶∏‡ßá‡¶∞ ‡¶∏‡¶¨‡ßÅ‡¶ú ‡¶™‡¶æ‡¶§‡¶æ‡¶ó‡ßÅ‡¶≤‡ßã ‡¶¨‡ßã‡¶ù‡¶æ‡¶ö‡ßç‡¶õ‡ßá
- "‡¶∏‡ßã‡¶®‡¶æ‡¶∞ ‡¶ü‡ßã‡¶™‡¶∞" = ‡¶Ü‡¶®‡¶æ‡¶∞‡¶∏‡ßá‡¶∞ ‡¶π‡¶≤‡ßÅ‡¶¶ ‡¶∞‡¶ô‡ßá‡¶∞ ‡¶´‡¶≤‡ßá‡¶∞ ‡¶Ö‡¶Ç‡¶∂
- "‡¶¨‡¶® ‡¶•‡ßá‡¶ï‡ßá ‡¶¨‡ßá‡¶∞‡ßÅ‡¶≤" = ‡¶¨‡¶æ‡¶ó‡¶æ‡¶® ‡¶•‡ßá‡¶ï‡ßá ‡¶™‡¶æ‡¶ï‡¶æ ‡¶π‡¶Ø‡¶º‡ßá ‡¶¨‡ßá‡¶∞‡ßã‡¶®‡ßã

‡¶™‡ßç‡¶∞‡¶∂‡ßç‡¶®: "‡¶è‡¶á ‡¶ß‡¶æ‡¶Å‡¶ß‡¶æ‡¶Ø‡¶º '‡¶ü‡¶ø‡¶Ø‡¶º‡ßá' ‡¶∂‡¶¨‡ßç‡¶¶‡¶ü‡¶ø ‡¶ï‡ßÄ ‡¶¨‡ßã‡¶ù‡¶æ‡¶Ø‡¶º?"
‡¶∏‡¶†‡¶ø‡¶ï ‡¶â‡¶§‡ßç‡¶§‡¶∞: "‡¶´‡¶≤‡ßá‡¶∞ ‡¶∏‡¶¨‡ßÅ‡¶ú ‡¶™‡¶æ‡¶§‡¶æ"
‡¶¨‡¶ø‡¶≠‡ßç‡¶∞‡¶æ‡¶®‡ßç‡¶§‡¶ø‡¶ï‡¶∞ ‡¶¨‡¶ø‡¶ï‡¶≤‡ßç‡¶™:
- "‡¶∏‡¶§‡ßç‡¶Ø‡¶ø‡¶ï‡¶æ‡¶∞‡ßá‡¶∞ ‡¶™‡¶æ‡¶ñ‡¶ø" (‡¶Ü‡¶ï‡ßç‡¶∑‡¶∞‡¶ø‡¶ï ‡¶Ö‡¶∞‡ßç‡¶•)
- "‡¶ü‡¶ø‡¶Ø‡¶º‡ßá ‡¶®‡¶æ‡¶Æ‡ßá‡¶∞ ‡¶ï‡ßã‡¶® ‡¶¨‡ßç‡¶Ø‡¶ï‡ßç‡¶§‡¶ø" (‡¶®‡¶æ‡¶Æ‡ßá‡¶∞ ‡¶∏‡¶æ‡¶¶‡ßÉ‡¶∂‡ßç‡¶Ø)
- "‡¶∏‡ßã‡¶®‡¶æ‡¶∞ ‡¶Æ‡ßÅ‡¶ï‡ßÅ‡¶ü" (‡¶Ö‡¶®‡ßç‡¶Ø ‡¶∞‡ßÇ‡¶™‡¶ï‡ßá‡¶∞ ‡¶∏‡¶æ‡¶•‡ßá ‡¶Æ‡¶ø‡¶∂‡ßç‡¶∞‡¶£)

**‡¶ó‡ßÅ‡¶∞‡ßÅ‡¶§‡ßç‡¶¨‡¶™‡ßÇ‡¶∞‡ßç‡¶£ ‡¶®‡¶ø‡¶∞‡ßç‡¶¶‡ßá‡¶∂‡¶®‡¶æ:**
- ‡¶¶‡ßç‡¶¨‡ßç‡¶Ø‡¶∞‡ßç‡¶•‡¶ï ‡¶∂‡¶¨‡ßç‡¶¶‡¶ü‡¶ø ‡¶Ö‡¶¨‡¶∂‡ßç‡¶Ø‡¶á ‡¶ß‡¶æ‡¶Å‡¶ß‡¶æ‡¶∞ ‡¶Æ‡¶ß‡ßç‡¶Ø‡ßá ‡¶•‡¶æ‡¶ï‡¶æ ‡¶ï‡ßã‡¶® ‡¶∂‡¶¨‡ßç‡¶¶/‡¶¨‡¶æ‡¶ï‡ßç‡¶Ø‡¶æ‡¶Ç‡¶∂ ‡¶π‡¶§‡ßá ‡¶π‡¶¨‡ßá
- ‡¶â‡¶§‡ßç‡¶§‡¶∞ "{correct_answer}" ‡¶ï‡ßá ‡¶¶‡ßç‡¶¨‡ßç‡¶Ø‡¶∞‡ßç‡¶•‡¶ï ‡¶∂‡¶¨‡ßç‡¶¶ ‡¶π‡¶ø‡¶∏‡ßá‡¶¨‡ßá ‡¶¨‡ßç‡¶Ø‡¶¨‡¶π‡¶æ‡¶∞ ‡¶ï‡¶∞‡¶¨‡ßá‡¶® ‡¶®‡¶æ
- ‡¶™‡ßç‡¶∞‡¶∂‡ßç‡¶® ‡¶è‡¶¨‡¶Ç ‡¶∏‡¶¨ ‡¶¨‡¶ø‡¶ï‡¶≤‡ßç‡¶™ ‡¶â‡¶§‡ßç‡¶§‡¶∞ ‡¶¨‡¶æ‡¶Ç‡¶≤‡¶æ‡¶Ø‡¶º ‡¶π‡¶¨‡ßá
- ‡¶™‡ßç‡¶∞‡¶∂‡ßç‡¶®‡¶ü‡¶ø "‡¶è‡¶á ‡¶ß‡¶æ‡¶Å‡¶ß‡¶æ‡¶Ø‡¶º '___' ‡¶∂‡¶¨‡ßç‡¶¶‡¶ü‡¶ø ‡¶ï‡ßÄ ‡¶¨‡ßã‡¶ù‡¶æ‡¶Ø‡¶º?" ‡¶¨‡¶æ "‡¶è‡¶á ‡¶ß‡¶æ‡¶Å‡¶ß‡¶æ‡¶Ø‡¶º '___' ‡¶¨‡¶≤‡¶§‡ßá ‡¶ï‡ßÄ ‡¶¨‡ßã‡¶ù‡¶æ‡¶®‡ßã ‡¶π‡¶Ø‡¶º‡ßá‡¶õ‡ßá?" ‡¶´‡¶∞‡¶Æ‡ßç‡¶Ø‡¶æ‡¶ü‡ßá
- ‡¶¶‡ßç‡¶¨‡ßç‡¶Ø‡¶∞‡ßç‡¶•‡¶ï ‡¶∂‡¶¨‡ßç‡¶¶‡¶ü‡¶ø ‡¶¨‡¶æ‡¶Ç‡¶≤‡¶æ‡¶Ø‡¶º ‡¶∞‡¶æ‡¶ñ‡ßÅ‡¶® ‡¶è‡¶¨‡¶Ç ‡¶ß‡¶æ‡¶Å‡¶ß‡¶æ‡¶∞ ‡¶ü‡ßá‡¶ï‡ßç‡¶∏‡¶ü ‡¶•‡ßá‡¶ï‡ßá ‡¶π‡ßÅ‡¶¨‡¶π‡ßÅ ‡¶®‡¶ø‡¶®
- ‡¶¨‡¶ø‡¶ï‡¶≤‡ßç‡¶™ ‡¶â‡¶§‡ßç‡¶§‡¶∞‡¶ó‡ßÅ‡¶≤‡ßã ‡¶∏‡¶π‡¶ú ‡¶¨‡¶æ‡¶Ç‡¶≤‡¶æ‡¶Ø‡¶º ‡¶π‡¶¨‡ßá
- ‡¶∏‡¶†‡¶ø‡¶ï ‡¶â‡¶§‡ßç‡¶§‡¶∞‡¶ü‡¶ø ‡¶∞‡ßÇ‡¶™‡¶ï‡ßá‡¶∞ ‡¶Ü‡¶∏‡¶≤ ‡¶Ö‡¶∞‡ßç‡¶• ‡¶π‡¶§‡ßá ‡¶π‡¶¨‡ßá
- ‡¶≠‡ßÅ‡¶≤ ‡¶¨‡¶ø‡¶ï‡¶≤‡ßç‡¶™‡¶ó‡ßÅ‡¶≤‡ßã ‡¶Ø‡ßÅ‡¶ï‡ßç‡¶§‡¶ø‡¶∏‡¶Ç‡¶ó‡¶§ ‡¶ï‡¶ø‡¶®‡ßç‡¶§‡ßÅ ‡¶≠‡ßç‡¶∞‡¶æ‡¶®‡ßç‡¶§ ‡¶π‡¶§‡ßá ‡¶π‡¶¨‡ßá

**‡¶™‡ßç‡¶∞‡¶§‡ßç‡¶Ø‡¶æ‡¶∂‡¶ø‡¶§ JSON ‡¶Ü‡¶â‡¶ü‡¶™‡ßÅ‡¶ü:**
{{
  "ambiguous_word": "‡¶ß‡¶æ‡¶Å‡¶ß‡¶æ‡¶∞ ‡¶Æ‡¶ß‡ßç‡¶Ø‡ßá ‡¶•‡¶æ‡¶ï‡¶æ ‡¶¶‡ßç‡¶¨‡ßç‡¶Ø‡¶∞‡ßç‡¶•‡¶ï ‡¶∂‡¶¨‡ßç‡¶¶/‡¶¨‡¶æ‡¶ï‡ßç‡¶Ø‡¶æ‡¶Ç‡¶∂ (‡¶â‡¶§‡ßç‡¶§‡¶∞ '{correct_answer}' ‡¶®‡¶Ø‡¶º)",
  "question": "‡¶è‡¶á ‡¶ß‡¶æ‡¶Å‡¶ß‡¶æ‡¶Ø‡¶º '____' ‡¶∂‡¶¨‡ßç‡¶¶‡¶ü‡¶ø ‡¶ï‡ßÄ ‡¶¨‡ßã‡¶ù‡¶æ‡¶Ø‡¶º?",
  "options": [
    "‡¶∏‡¶†‡¶ø‡¶ï ‡¶¨‡¶æ‡¶Ç‡¶≤‡¶æ ‡¶â‡¶§‡ßç‡¶§‡¶∞",
    "‡¶Ø‡ßÅ‡¶ï‡ßç‡¶§‡¶ø‡¶∏‡¶Ç‡¶ó‡¶§ ‡¶≠‡ßÅ‡¶≤ ‡¶¨‡¶æ‡¶Ç‡¶≤‡¶æ ‡¶â‡¶§‡ßç‡¶§‡¶∞ ‡ßß",
    "‡¶Ø‡ßÅ‡¶ï‡ßç‡¶§‡¶ø‡¶∏‡¶Ç‡¶ó‡¶§ ‡¶≠‡ßÅ‡¶≤ ‡¶¨‡¶æ‡¶Ç‡¶≤‡¶æ ‡¶â‡¶§‡ßç‡¶§‡¶∞ ‡ß®", 
    "‡¶Ø‡ßÅ‡¶ï‡ßç‡¶§‡¶ø‡¶∏‡¶Ç‡¶ó‡¶§ ‡¶≠‡ßÅ‡¶≤ ‡¶¨‡¶æ‡¶Ç‡¶≤‡¶æ ‡¶â‡¶§‡ßç‡¶§‡¶∞ ‡ß©"
  ],
  "correct_option": "‡¶∏‡¶†‡¶ø‡¶ï ‡¶¨‡¶æ‡¶Ç‡¶≤‡¶æ ‡¶â‡¶§‡ßç‡¶§‡¶∞"
}}

**‡¶Æ‡¶®‡ßá ‡¶∞‡¶æ‡¶ñ‡¶¨‡ßá‡¶®:** ambiguous_word ‡¶´‡¶ø‡¶≤‡ßç‡¶°‡ßá ‡¶∂‡ßÅ‡¶ß‡ßÅ‡¶Æ‡¶æ‡¶§‡ßç‡¶∞ ‡¶ß‡¶æ‡¶Å‡¶ß‡¶æ‡¶∞ ‡¶ü‡ßá‡¶ï‡ßç‡¶∏‡¶ü ‡¶•‡ßá‡¶ï‡ßá ‡¶ï‡ßã‡¶® ‡¶∂‡¶¨‡ßç‡¶¶/‡¶¨‡¶æ‡¶ï‡ßç‡¶Ø‡¶æ‡¶Ç‡¶∂ ‡¶¨‡ßç‡¶Ø‡¶¨‡¶π‡¶æ‡¶∞ ‡¶ï‡¶∞‡ßÅ‡¶®, ‡¶â‡¶§‡ßç‡¶§‡¶∞ "{correct_answer}" ‡¶¨‡ßç‡¶Ø‡¶¨‡¶π‡¶æ‡¶∞ ‡¶ï‡¶∞‡¶¨‡ßá‡¶® ‡¶®‡¶æ‡•§

‡¶è‡¶ñ‡¶® ‡¶â‡¶™‡¶∞‡ßá‡¶∞ ‡¶ß‡¶æ‡¶Å‡¶ß‡¶æ‡¶∞ ‡¶ú‡¶®‡ßç‡¶Ø semantic ambiguity task ‡¶§‡ßà‡¶∞‡¶ø ‡¶ï‡¶∞‡ßÅ‡¶®‡•§"""

        max_retries = 3
        for attempt in range(max_retries):
            try:
                print(f"    ü§ñ Generating semantic task (attempt {attempt + 1}/{max_retries})...")
                
                response = requests.post(OLLAMA_URL, json={
                    "model": OLLAMA_MODEL,
                    "prompt": prompt,
                    "stream": False,
                    "options": {
                        "temperature": 0.7,
                        "top_p": 0.9,
                        "top_k": 40
                    }
                }, timeout=300)  # 5 minutes timeout for semantic analysis
                
                if response.status_code == 200:
                    result = response.json()
                    response_text = result.get('response', '')
                    
                    # Extract JSON from response
                    try:
                        # Find JSON in the response
                        start_idx = response_text.find('{')
                        end_idx = response_text.rfind('}') + 1
                        
                        if start_idx != -1 and end_idx > start_idx:
                            json_str = response_text[start_idx:end_idx]
                            parsed_json = json.loads(json_str)
                            
                            ambiguous_word = parsed_json.get('ambiguous_word', '')
                            question = parsed_json.get('question', '')
                            options = parsed_json.get('options', [])
                            correct_option = parsed_json.get('correct_option', '')
                            
                            # Validate the generated task
                            if (ambiguous_word and question and len(options) == 4 and 
                                correct_option and correct_option in options):
                                
                                # Check that ambiguous_word is from riddle, not the answer
                                if ambiguous_word.strip().lower() == correct_answer.strip().lower():
                                    print(f"    ‚ùå Ambiguous word '{ambiguous_word}' is the same as answer '{correct_answer}' (attempt {attempt + 1})")
                                    continue
                                
                                # Check that ambiguous_word appears in the riddle
                                if ambiguous_word not in riddle:
                                    print(f"    ‚ùå Ambiguous word '{ambiguous_word}' not found in riddle text (attempt {attempt + 1})")
                                    continue
                                
                                # Randomize the order of options
                                random.shuffle(options)
                                
                                # Additional quality validation
                                if self.validate_task_quality(question, options, correct_option, riddle):
                                    correct_index = options.index(correct_option)
                                    print(f"    ‚úÖ Generated semantic task for ambiguous word: '{ambiguous_word}' (correct at index {correct_index})")
                                    return {
                                        'ambiguous_word': ambiguous_word,
                                        'question': question,
                                        'options': options,
                                        'correct_option': correct_option
                                    }
                                else:
                                    print(f"    ‚ùå Task failed quality validation (attempt {attempt + 1})")
                            else:
                                print(f"    ‚ùå Incomplete semantic task generated (attempt {attempt + 1})")
                                print(f"         Word: {bool(ambiguous_word)}, Question: {bool(question)}")
                                print(f"         Options: {len(options)}/4, Correct: {bool(correct_option)}")
                        else:
                            print(f"    ‚ùå No JSON found in response (attempt {attempt + 1})")
                    
                    except json.JSONDecodeError as e:
                        print(f"    ‚ùå JSON parsing error (attempt {attempt + 1}): {e}")
                else:
                    print(f"    ‚ùå API error {response.status_code} (attempt {attempt + 1})")
                
                # Wait before retry
                if attempt < max_retries - 1:
                    wait_time = 2 ** attempt  # Exponential backoff
                    print(f"    ‚è≥ Waiting {wait_time}s before retry...")
                    time.sleep(wait_time)
            
            except Exception as e:
                print(f"    ‚ùå Exception during generation (attempt {attempt + 1}): {e}")
                if attempt < max_retries - 1:
                    time.sleep(2)
        
        return None
    
    def process_riddle(self, riddle_data: Dict[str, Any]) -> Optional[Dict[str, Any]]:
        """Process a single riddle to generate semantic ambiguity task."""
        riddle_id = riddle_data['riddle_id']
        riddle = riddle_data['riddle']
        answer = riddle_data['ans']
        
        print(f"\nüîç Processing riddle {riddle_id}: {riddle[:50]}...")
        
        # Generate semantic ambiguity task
        task_data = self.generate_semantic_task(riddle, answer)
        
        if task_data:
            # Create final semantic ambiguity task
            semantic_task = {
                'id': riddle_id,
                'riddle': riddle,
                'ans': answer,
                'ambiguous_word': task_data['ambiguous_word'],
                'question': task_data['question'],
                'options': task_data['options'],
                'correct_option': task_data['correct_option']
            }
            
            print(f"‚úÖ Successfully created semantic task for riddle {riddle_id}")
            return semantic_task
        else:
            error_msg = "Failed to generate semantic task after multiple attempts"
            print(f"‚ùå {error_msg}")
            self.failed_riddles.append(riddle_id)
            self.save_failed_riddle(riddle_data, error_msg)
            return None
    
    def save_semantic_tasks(self, semantic_tasks: List[Dict[str, Any]]):
        """Save semantic ambiguity tasks to output file."""
        with open(OUTPUT_FILE, 'w', encoding='utf-8') as f:
            json.dump(semantic_tasks, f, indent=2, ensure_ascii=False)
        print(f"üíæ Saved {len(semantic_tasks)} semantic tasks to {OUTPUT_FILE}")
    
    def process_all_riddles(self, start_idx: int = 0, end_idx: Optional[int] = None):
        """Process all riddles to generate semantic ambiguity tasks."""
        
        # Check Ollama connection first
        if not self.check_ollama_connection():
            print("‚ùå Cannot proceed without Ollama connection. Please start Ollama and try again.")
            return
        
        # Load riddles
        print(f"üìö Loading riddles from {RIDDLES_FILE}...")
        try:
            with open(RIDDLES_FILE, 'r', encoding='utf-8') as f:
                all_riddles = json.load(f)
        except Exception as e:
            print(f"‚ùå Error loading riddles: {e}")
            return
        
        # Determine range
        total_riddles = len(all_riddles)
        end_idx = end_idx if end_idx is not None else total_riddles
        riddles_to_process = all_riddles[start_idx:end_idx]
        
        print(f"üìä Total riddles in dataset: {total_riddles}")
        print(f"üìä Previously processed: {len(self.processed_riddles)}")
        print(f"üìä Range to process: {start_idx} to {end_idx-1} ({len(riddles_to_process)} riddles)")
        
        # Load existing semantic tasks
        existing_tasks = []
        if os.path.exists(OUTPUT_FILE):
            try:
                with open(OUTPUT_FILE, 'r', encoding='utf-8') as f:
                    existing_tasks = json.load(f)
            except Exception:
                existing_tasks = []
        
        # Process riddles
        processed_count = 0
        failed_count = 0
        
        for i, riddle_data in enumerate(riddles_to_process):
            riddle_id = riddle_data['riddle_id']
            
            # Skip if already processed
            if riddle_id in self.processed_riddles:
                print(f"‚è≠Ô∏è  Skipping already processed riddle {riddle_id}")
                continue
            
            try:
                semantic_task = self.process_riddle(riddle_data)
                
                if semantic_task:
                    existing_tasks.append(semantic_task)
                    self.processed_riddles.add(riddle_id)
                    processed_count += 1
                    
                    # Save progress every 10 riddles
                    if processed_count % 10 == 0:
                        self.save_semantic_tasks(existing_tasks)
                        self.save_progress()
                        print(f"üíæ Progress saved: {processed_count} processed, {failed_count} failed")
                else:
                    failed_count += 1
                
            except Exception as e:
                print(f"‚ùå Error processing riddle {riddle_id}: {e}")
                failed_count += 1
                self.failed_riddles.append(riddle_id)
                self.save_failed_riddle(riddle_data, str(e))
        
        # Final save
        if existing_tasks:
            self.save_semantic_tasks(existing_tasks)
        self.save_progress()
        
        print(f"\nüéâ Semantic ambiguity task generation completed!")
        print(f"‚úÖ Successfully processed: {processed_count}")
        print(f"‚ùå Failed: {failed_count}")
        print(f"üìÅ Output saved to: {OUTPUT_FILE}")
        if failed_count > 0:
            print(f"üìÅ Failed riddles logged to: {FAILED_FILE}")

def main():
    """Main function to run semantic ambiguity task generation."""
    generator = SemanticAmbiguityGenerator()
    
    print("üéØ Bengali Riddle Semantic Ambiguity Task Generator")
    print("=" * 50)
    
    # For testing, process first 5 riddles
    generator.process_all_riddles(start_idx=0, end_idx=5)

if __name__ == "__main__":
    main()
